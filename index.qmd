---
title: "Tone Matters: Sentiment Classification of Support Tweets Using VADER and XGBoost"
subtitle: ""
author: "Samantha Chickeletti & Michael Alfrey (Advisor: Dr. Cohen)"
date: "`r Sys.Date()`"
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)


## Introduction

In today’s digital landscape, customer support conversations increasingly take place over chat and social media platforms. These short-form exchanges are often emotionally charged and can signal a customer’s satisfaction, frustration, or potential escalation. Understanding the emotional tone behind these messages is critical for improving service quality, anticipating customer needs, and enhancing the overall customer experience. Yet, analyzing this kind of shorthand-heavy language presents a unique challenge for traditional sentiment analysis models.

This project explores how VADER (Valence Aware Dictionary for sEntiment Reasoning), a lexicon-based sentiment analysis tool, can classify tone in real customer support messages [@hutto2014vader]. Its design prioritizes speed and interpretability, making it ideal for short, informal content like tweets and chat messages. VADER’s scoring mechanism is particularly sensitive to social media features such as emojis, capitalization, and punctuation, which are often critical to conveying tone in these environments [@barik2024vader].

To build a full machine learning pipeline around VADER, we will use its sentiment scores (positive, neutral, negative) as labels and train an XGBoost classifier using TF-IDF features extracted from the message text. XGBoost is well-suited for this task because it performs efficiently with sparse, high-dimensional data and eliminates the need to hand-label messages or train a separate sentiment model from scratch.

The dataset selected for this project is the “Customer Support on Twitter” dataset from Kaggle, which contains real-world support interactions between users and brands such as Apple, Amazon, and Comcast. The messages are short, informal, and emotionally expressive—closely mirroring real-world customer support scenarios—and make the dataset ideal for sentiment analysis and predictive modeling.


Natural Language Processing (NLP) has become a vital tool for understanding customer sentiment across digital platforms. A variety of approaches have been proposed in the literature, from lexicon-based models such as VADER to machine learning methods like XGBoost. This review highlights the studies that informed the methodological design of our project.

#### Lexicon-Based Sentiment Analysis

The foundation of our sentiment scoring approach is VADER, a rule-based model that excels at detecting sentiment in informal, short-form text such as tweets and chat messages [@hutto2014vader]. VADER is well-suited for analyzing customer service conversations because it accounts for:

- Capitalization: (e.g., `"AWESOME"` → increases intensity)

- Punctuation: (e.g., `!` → amplifies sentiment)

- Slang, emojis, and emoticons: (e.g., `:)` → amplifies sentiment)

- Negation: (e.g., `"not good"` → polarity reversal)

Recent research continues to support and expand on VADER's use. Barik and Misra [@barik2024vader] evaluated an improved VADER lexicon in analyzing e-commerce reviews and emphasized its interpretability and processing speed. Chadha and Aryan [@chadha2023vader] also confirmed VADER’s reliability in sentiment classification tasks, noting its effectiveness in fast-paced business contexts. Youvan [@youvan2024vader] offered a comprehensive review of VADER’s core logic, highlighting its treatment of intensifiers, negations, and informal expressions.

#### Machine Learning for Sentiment Classification

To complement VADER’s labeling, we incorporate XGBoost, an efficient and scalable gradient boosting algorithm, as a supervised classifier. Lestari et al. [@lestari2025xgboost] compared XGBoost with AdaBoost for movie review classification and found XGBoost achieved higher accuracy and generalizability. Sefara and Rangata [@sefara2024domain] also found XGBoost to be the most effective model for classifying domain-specific tweets, outperforming Logistic Regression and SVM in both performance and efficiency. Lu and Schelle [@lu2025tesla] demonstrated how XGBoost could be used to extract interpretable feature importance from tweet sentiment, providing additional value for insights and decision-making.


## Methods

#### Preprocessing and Sentiment Labeling with VADER
Before applying VADER to assign sentiment labels to tweets, we preprocessed tweets by removing URLs, user mentions, punctuation, and English stopwords. While VADER can handle informal text, this step was performed to improve text uniformity and prepare for downstream modeling. We then applied the VADER sentiment analyzer to label tweets as Positive, Neutral, or Negative based on their compound score. The compound sentiment score is computed as:

$$
\text{compound} = \frac{\sum_{i=1}^{n} s_i}{\sqrt{\sum_{i=1}^{n} s_i^2} + \alpha}
$$
Where $s_i$ is the sentiment score for each word or token and $\alpha$ is a normalization constant (typically set to 15).

The final sentiment labels are then assigned using the following thresholds:

* *Positive* if compound ≥ 0.05

* *Neutral* if -0.05 < compound < 0.05

* *Negative* if compound ≤ -0.05
<br>

#### Example VADER Scoring:

>> "I’ve been waiting over an HOUR and still no response… this is ridiculous!!!"
<br>

| Feature         | Detected Element       | VADER Response                  |Score Impact |
|----------------|------------------------|---------------------------------|-------------|
| Capitalization | "HOUR", "STILL"        | Increases intensity             | -0.10       |
| Punctuation    | "..." and "!!!"        | Amplifies negative sentiment    | -0.25       |
| Lexicon Match  | "ridiculous"           | Strong negative valence         | -0.25       |
| Overall Tone   | Complaint/frustration  | Strongly negative               | -0.15       |
| **Final Compound**       |                     | **-0.75**   |

This tweet yields a compound score of approximately –0.75 and is labeled as negative. These labeled examples served as training data for our classification model.


By relying on VADER to label tweets without requiring manual annotation, we create a foundation for downstream supervised learning. This aligns with findings by Lu (2025), who demonstrated that VADER-labeled tweets combined with TF-IDF and XGBoost achieved performance comparable to manually labeled datasets [@lu2025tesla].

#### TF-IDF 

OLD:
After labeling each tweet with a sentiment category using VADER, the next step is to prepare the message text for machine learning. To do this, we convert the raw text messages into numerical features using Term Frequency–Inverse Document Frequency (TF-IDF). This step will be essential to enabling the XGBoost classifier to process textual input. TF-IDF is a widely used statistical tool capable of capturing the importance of words relative to both the individual message and the larger corpus. It is particularly effective for datasets like ours: short-form, informal, and sparse in structure. Tweets in customer support often include abbreviations, slang, or repetition, and TF-IDF helps retain the meaningful patterns without overwhelming the classifier with irrelevant frequently used words. In our pipeline, this vectorization bridges the gap between qualitative scoring of VADER with the quantitative input required for supervised learning. Studies have shown that combining TF-IDF with tree-based models yields strong results in sentiment analysis: Lestari et al. (2025) found this combination improved accuracy and generalizability across multiple datasets, while Sefara and Rangata (2024) demonstrated its effectiveness for classifying domain-specific tweets [@lestari2025xgboost; @sefara2024domain]. By aligning the language structure with statistical weight, TF-IDF enhances the model's ability to prioritize the most discriminative features for downstream classification.

NEW:<br>
To convert tweets into numerical features for modeling, we employ Term Frequency–Inverse Document Frequency (TF-IDF), a technique that quantifies how important each word is within the context of both the individual tweet and the overall corpus.

Term Frequency (TF) measures how often a word appears in a single tweet (i.e., domain) relative to the total number of words in that tweet:

$$
\text{TF}_{w_n} = \frac{g_{w_n}^{d_m}}{T_{d_m}}
$$
Where:<br>
* $w_n$ is the $n^{\text{th}}$ word in domain $d_m$ (a tweet) <br>
* $g_{w_n}^{d_m}$ is the number of times word $w_n$ occurs in domain $d_m$ <br>
* $T_{d_m}$ is the total number of words in domain $d_m$ <br>

Example:<br>
If the word delay appears twice in a 50-word tweet, its term frequency is:

$$
\text{TF}_{w_n} = \frac{2}{50} = 0.04
$$


Inverse Document Frequency (IDF) evaluates how unique or informative a word is across the full set of tweets. Common words receive lower IDF scores, while rare or distinctive words receive higher scores:

$$
\text{IDF}_{w_n} = \log\left(\frac{T_{d_m}}{N_{w_n}}\right)
$$

Where: <br>
* $N_{w_n}$ is the number of documents that contain word w_n <br>

Example: <br>
If *delay* appears in 5 out of 500,000 tweets, its IDF will be much higher than that of *hello*, which may appear in 10,000 tweets.


Finally, TF-IDF combines these two metrics to weight each word by how frequently it appears in a tweet and how rare it is across the full dataset:

$$
\text{TF-IDF}_{w_n} = \text{TF}_{w_n} \times \text{IDF}_{w_n}
$$

This process highlights terms that are both prominent in a tweet and distinctive across the dataset, making TF-IDF a powerful and interpretable technique for feature extraction in sentiment analysis pipelines [@barik2024vader].


#### XGBoost 

With tweets now represented as TF-IDF vectors and labeled with sentiment scores from VADER, we train a XGBoost (Extreme Gradient Boosting) classifier to detect patterns in tone and emotion across messages. XGBoost is a powerful, scalable tree-based ensemble learning algorithm that builds decision trees sequentially. It optimizes performance by minimizing a loss function over each iteration. This classifier's ability to handle high-dimensional, sparse input like TF-IDF vectors makes it an excellent fit for our dataset. By learning from VADER’s labeled examples, XGBoost will extend the sentiment classification process beyond just lexicon rules and will enable it to be generalized to unseen or new messages. For example, while VADER may recognize “unacceptable” as a negative word, XGBoost may learn that the phrase “still no reply” often occurs in complaints and weight it accordingly even if it’s less emotionally charged on its own.
This predictive layer is what supports scalable automation and could serve in the future as the foundation of real-time sentiment monitoring or analysis of escalation risks. Prior research highlights XGBoost’s effectiveness in similar NLP pipelines, particularly when combined with TF-IDF to balance performance and interpretability [@lestari2025xgboost; @sefara2024domain; @lu2025tesla]. Together, TF-IDF and XGBoost turn VADER’s interpretability into actionability. This layered approach positions our model not only as a tool for retrospective analysis, but as a scalable framework for monitoring customer sentiment in fast-paced service environments.

#### Evaluation Metrics

Once the sentiment labels were used to train a classification model, it became essential to evaluate how effectively the model performs on new, unseen data. In this project, we use four standard evaluation metrics accuracy, precision, recall, and F1 score to assess model performance.

- *Accuracy*: The proportion of correctly predicted labels across all tweets. While it provides an overall gauge, it is less informative when class imbalance exists.

- *Precision*: The proportion of correct predictions among all tweets the model labeled as a given class.High precision for the negative  class is especially important to avoid raising false alerts.

- *Recall*: The proportion of actual sentiment instances that were correctly identified. High recall ensures the model captures most frustrated or escalated tweets.

- *F1 Score*: The harmonic mean of precision and recall. This is especially useful in sentiment analysis, where both false positives and false negatives can lead to operational issues (e.g., missing angry customers or falsely escalating satisfied ones).

These metrics were selected to account for class imbalance, which is common in sentiment datasets. For instance, neutral tweets often dominate volume, while negative tweets are more operationally important in customer service. Therefore, we paid close attention to class-specific precision and recall, especially for the negative class, to ensure that frustrated customer messages were identified without over-triggering on neutral ones [@barik2024ivader; @gandy2025public].

> *Note: Some parts of this project were assisted by ChatGPT for writing support and citation formatting. All content was reviewed and edited by the authors to ensure accuracy and originality.*


## Analysis and Results

### Data Exploration and Visualization

The data was sourced from Kaggle’s Customer Support on Twitter dataset, which contains over 2.8 million tweets between customers and major companies. Each entry includes:

- Tweet text

- Author ID

- Timestamp

- Inbound or outbound label 

- Associated response tweet ID 

Note: Response_tweet_id and in_response_to_tweet_id contained a high number of missing values, these were not relevant to the sentiment classification task and were not used in downstream modeling.
<br>

To prepare the data for analysis, the tweet text was cleaned by removing URLs, mentions, hashtags, punctuation, and stopwords. The tweets were then labeled using the VADER sentiment analyzer, assigning a compound score ranging from -1 (most negative) to +1 (most positive).

After applying VADER, the sentiment distribution across all tweets was: 53.3% Positive, 26.0% Neutral, and 20.7% Negative. This distribution reflects the generally service-oriented tone of support conversations, with a notable proportion of unresolved or escalated issues.

```{r, echo=FALSE, out.width="70%", fig.cap="Figure: Sentiment Distribution of Customer Support Tweets"}
knitr::include_graphics("sentiment_distribution.png")
```

One surprising find was the high percentage of positive inbound tweets. While we expected more complaints or frustration, it appears many customers tweet to thank support agents after resolution. Additionally, predefined responses from companies (“Please send us a DM...”) likely contribute to a more neutral or polite tone overall.

However, frequent use of words like “still,” “waiting,” and “no response” did appear in the negative tweets, often paired with emojis or punctuation, highlighting specific customer pain points in response time and resolution.

<div style="text-align: center;">
  <img src="PosWC.png" width="70%">
  <img src="NuWC.png" width="75%">
  <img src="NegWC.png" width="70%">
  <p><strong>Figure:</strong> Word Clouds by Sentiment Class – Positive, Neutral, and Negative</p>
</div>
<br>

**The next steps will involve:**

- TF-IDF vectorization
- XGBoost classification modeling
- Model performance evaluation (accuracy, precision, recall, F1)


```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
